{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronPopRecording: #Suppose to be one file\n",
    "    metadata_datanames=['noNeurons', 'dt', 'totalTimesteps', 'neuronPopId', 'simTime']\n",
    "    def __init__(self, neuronPop_id : int):\n",
    "        self.neuronPop_id=neuronPop_id\n",
    "    def append_metadata(self, metadata_list : list):\n",
    "        self.metadata=metadata_list\n",
    "    def append_spiketimes(self, N_index : int, spiketimes_list : list):\n",
    "        setattr(self, \"Neuron_%s\" % (N_index), spiketimes_list)\n",
    "    def create_firing_matrix(self):\n",
    "        self.F_matrix=np.zeros(shape=(self.metadata[2], self.metadata[0]))\n",
    "        for neuron in dir(self):\n",
    "            if neuron.startswith(\"Neuron\"):\n",
    "                neuron_index=int(neuron.split('_')[1])\n",
    "                spiketimes=self.__dict__[neuron]\n",
    "                for st in spiketimes:\n",
    "                    self.F_matrix[int(st/self.metadata[1])-1, neuron_index]=1\n",
    "\n",
    "class OutputRecordingList: #Compendium of all recordings\n",
    "#    def __iter__(self):\n",
    "#        for attr, value in self.__dict__.iteritems():\n",
    "#            yield attr, value\n",
    "    def get(self):\n",
    "        return self.__dict__\n",
    "    def append(self, var : NeuronPopRecording):\n",
    "        setattr(self, \"NeuronPop_%s\" % (var.neuronPop_id), var)\n",
    "\n",
    "#Here we use split = to get the name and the values, then split the second with commas to get the spike-time list\n",
    "def read_reasterplot_file_into_object(neuronPop_files):\n",
    "    all_recordingsST=OutputRecordingList()\n",
    "    for i, file in enumerate(neuronPop_files):\n",
    "        with open(file, \"r\") as file:\n",
    "            lines=file.readlines()\n",
    "            for line in lines:\n",
    "                if line.startswith('M'):\n",
    "                    subline=line.split('=')\n",
    "                    neuronpop_id=int(subline[0].split('_')[1])\n",
    "                    metadata_list=subline[1].split(',')\n",
    "\n",
    "                    metadata_list[0]=int(metadata_list[0])\n",
    "                    metadata_list[1]=float(metadata_list[1])\n",
    "                    metadata_list[2]=int(metadata_list[2])\n",
    "                    metadata_list[3]=int(metadata_list[3])\n",
    "                    metadata_list[4]=float(metadata_list[4])\n",
    "\n",
    "                    recording=NeuronPopRecording(neuronpop_id)\n",
    "                    recording.append_metadata(metadata_list)\n",
    "                    all_recordingsST.append(recording)\n",
    "\n",
    "                elif line.startswith('N'):\n",
    "                    subline=line.split('=')\n",
    "                    idline=subline[0].split('_')\n",
    "                    neuronpop_id=int(idline[1])\n",
    "                    neuron_id=int(idline[2])\n",
    "\n",
    "                    spiketimes=list()\n",
    "                    for i in subline[1].split(','):\n",
    "                        if i=='':\n",
    "                            continue\n",
    "                        elif i=='\\n':\n",
    "                            continue\n",
    "                        else:\n",
    "                            spiketimes.append(float(i))\n",
    "                    all_recordingsST.__getattribute__(list(all_recordingsST.__dict__.keys())[neuronpop_id]).__getattribute__(\"append_spiketimes\").__call__(neuron_id, spiketimes)\n",
    "                else:\n",
    "                    print('Oversight error')\n",
    "                    raise Exception\n",
    "        all_recordingsST.append(recording)\n",
    "    return all_recordingsST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsed spike times file reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AnalyseData.Rmd',\n",
       " 'hetero_analyser_mono_dendrite.ipynb',\n",
       " 'LoadData.R',\n",
       " 'ParsedFileReader.ipynb',\n",
       " 'README.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#File reading here (files are always iterated on alphabetical order)\n",
    "parsedOutput_string='_ParsedOutput.dat'\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "neuronPop_files = [f for f in os.listdir(base_dir) if f.endswith(parsedOutput_string)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading parsed spike times file (Neuron output) and creating firing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NeuronPop_0': [0, 2, 4]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recordings=read_reasterplot_file_into_object(neuronPop_files)\n",
    "for attr in all_recordings.__dict__:\n",
    "    print(attr)\n",
    "    all_recordings.__getattribute__(attr).__getattribute__(\"create_firing_matrix\").__call__()\n",
    "    ##Up until here everything woks as expected"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rasterplot parsing code to spike times\n",
    "(They will be lacking non-firing neurons, and there is no metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File reading here (files are always iterated on alphabetical order)\n",
    "rasterplot_string='Rasterplot.dat'\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "rasterplot_files = [f for f in os.listdir(base_dir) if f.endswith(rasterplot_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterdata=pd.read_table(rasterplot_files[0], comment='#')\n",
    "neuronPopIds=set(rasterdata['Pop_id'])\n",
    "neuronIds=set(rasterdata['Neuron_id'])\n",
    "all_recordings2=OutputRecordingList()\n",
    "for i in neuronPopIds:\n",
    "    all_recordings2.append(NeuronPopRecording(i))\n",
    "    for j in neuronIds:\n",
    "        spiketimes = rasterdata[rasterdata['Neuron_id']==j]\n",
    "        spiketimes= spiketimes[spiketimes['Pop_id']==i]\n",
    "        spiketimes = list(spiketimes[\"Spike_t\"])\n",
    "        all_recordings2.__getattribute__(list(all_recordings2.__dict__.keys())[i]).__getattribute__(\"append_spiketimes\").__call__(j, spiketimes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a4880536bc750f262d1b458e4fd4d611315d3098d58b77bd9c89b3237b9ab47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
